{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"My uni notes!! Courses comp3891 comp3211 comp2511 For full documentation visit mkdocs.org .","title":"Home"},{"location":"#my-uni-notes","text":"","title":"My uni notes!!"},{"location":"#courses","text":"comp3891 comp3211 comp2511 For full documentation visit mkdocs.org .","title":"Courses"},{"location":"comp2511-home/","text":"","title":"COMP2511"},{"location":"comp3211-home/","text":"lol nvm i dropped this course TOC Week 1 w1 recap","title":"COMP3211"},{"location":"comp3211-home/#lol-nvm-i-dropped-this-course","text":"","title":"lol nvm i dropped this course"},{"location":"comp3211-home/#toc","text":"","title":"TOC"},{"location":"comp3211-home/#week-1","text":"w1 recap","title":"Week 1"},{"location":"comp3891-home/","text":"TOC Recaps w1 recap w2 recap w3 recap","title":"COMP3891"},{"location":"comp3891-home/#toc","text":"","title":"TOC"},{"location":"comp3891-home/#recaps","text":"w1 recap w2 recap w3 recap","title":"Recaps"},{"location":"comp3211/w1/","text":"Single cycle processors Building a processor! Assume that we have an ISA. To build a processor, there are two major components to this: 1) Datapath - The datapath is reponsible for figuring out and processing data 2) Control - The control is to determine where data goes based off the input","title":"Single cycle processors"},{"location":"comp3211/w1/#single-cycle-processors","text":"","title":"Single cycle processors"},{"location":"comp3211/w1/#building-a-processor","text":"Assume that we have an ISA. To build a processor, there are two major components to this: 1) Datapath - The datapath is reponsible for figuring out and processing data 2) Control - The control is to determine where data goes based off the input","title":"Building a processor!"},{"location":"comp3891/w1/","text":"What is an OS? An operating system is the abstraction that helps connect userspace and hardware! There are many layers of abstractions built for us: we have C code thats been compiled, which relies on system libraries (think cstdlib), which makes use of syscalls which are provided by the OS! e.g. We never manually interact with the filesystem Distribute resources! Imagine multiple users (or processes) trying to run their program. How do we choose who evently recieves what data? the operating system is in charge of that! It could be done through a policy as well (quota, first come first serve, etc) from the perspective of the system, the OS is the software running in priviliged mode! this could be like ring0 or whatever but there are physical hardware checks (think lgdt, tss, etc in x86) Theres a flag set in hardware that shows if the current software can do more stuff (accesss memory, etc) Structure of a system? Theres two 'bubbles' of a system: We usually have userspace and kernel mode. Applications in userspace make use of system libraries; which are just normal libraries as well. Its just ordinary code that interacts with the kernel to get stuff done. If you think about it, everything lives somewhere on memory. The operating system has the ability to view memory and theres some memory that can only be touched by the OS. If processes want to do stuff that involve os actions, they need to make use of syscalls, which are like function calls but its a protected way of nicely asking the os to do something for you. These can be written by yourself but most often you want to do them via syscalls (open, close, read, etc). These syscalls are then created to have another abstraction layer (malloc, memcpy, etc) tldr; the operating system is just code that has more power and that lets it interact with hardware (like memory) System approaches How should we arrange an OS internally? There is a layered by layer approach: dependencies point downwards into the core of the system. For instance, the usermode would be in the shell of the system, with layers of abstraction behind each other, with processor management and memoryu management at the core! However, this isn't really realistic. A different implimentation is a monolithic kernel; everything is interlinked with everything else! Think linux, windows, etc. However, a general prevailing structure will usually form. Processes and threads Remember how we said the os needs to be able to run more than one thing? The processor will give the os the ability to do so, but the processor itself cannot run more than one thing at once unless you have multithreading: but you still want more processes than you ahve threads. what is a process? what is a thread? A process is closer to an abstraction of a thing that \"runs\", or a user level execution. It owns resources allocated for program execution. It encompasses one more more threads. A thread is the sequence of instruciotns that are ran. Think of processes as a space in memory of a thing to be executed, and a thread being the instructions that make up that process being ran the thread model Assume there is a multithreaded process: At the langauge level; that means that each thread within the process has its own separate stack that can still share state (global varaibles) since they live in the same memory. But for local variables, they should have their own local variables (per thread) scope local varialbes are per thread global variables are shared (written in the .bss segment i think) dynamically allocated variables could be local OR global... (think malloc() ) Scheduling So how do we run muiltiple processes on one thread? We can have a dispatcher (scheduler) that decides which process to run by having each process run for a few instructions, before returning back to the dispatcher which makes a jump. States have to be preserved in between (storing register data), loaded and restored. Using this, it appeares that multiple processes are running at once, but in reality only one program is active at one point. Thus, there is a model of having sequential processes with a single thread each \"running\" at the same time. When do we return back to the dispatcher? If you remember from our example of having programs scheduled in between, we jump between different processes by having program A run for a few instruction cycles before returning back to the dispatcher, which then decides on the next ready process to execute. How do we actually return back to the dispatcher in that instance? There is a feature within the CPU when certain hardware needs attention, it asks the CPU to stop executing its current instructions and then transition to the interrupt handler within the OS. Like a syscall, it forces a transition to the OS to timeout threads that have met its quota and transitions to the dispatcher (scheduler). How are processes created? The os doesn't like setting things itself; it likes being reactive. Normally, that means handing it over to an init system (think systemd and openrc) that handles starting up other processes and etc. Theres different types of processes as well: foreground processes and background processes (known as daemons) Processes can start other processes as well! think login prompts that start you into a desktop environment once you login. All these processes mostly just make use of one syscall to create new processes! how to processes end? normal exit (return 0) error exit (exit(1)) fatal error (runtime error, div 0) kileld by another process (sigterm, ctrl-c) implementation of processes What does the code/data that implements a process look like? It needs to hold metadata for the os to make use of, and is held within the process control block (PCB). The PCBs form a process table that shows Assume this is for a single thread/process model: process metadata would include: registers, program counter, stack pointer, process state, pointers to stack, text, data segments, process ID, cpu time used, children of CPU time, etc. these all are used by the operating system to control and make use of processes, like scheduling or terminating based off other processes. Threads/Process states there can be alot of variable thread or process states. Ideally, we should have as many running processes as there are threads in cpus. running -> ready - voluntary yield() - end of timeslice (quota) ready -> running running -> blocked - waiting for input (file, network, keyboard) - waiting for a timer sleep() - waiting for a resource to become avaliable blocked -> ready for the transition from runnign to ready for a thread, this could be a thread that is currently running, but its time budget is now used up and will be reassigned to a different process! It's still ready to run, its just not one of the ready threads. For ready -> running, the currently running task got stopped so we need to replace the thread to keep the cpu busy. For running -> blocked, something like a syscall could happen: a process wants to sleep(), or the process wants to use a syscall to fetch file contents. Its not current avaliable, so the thread becomes blocked. It's not allowed to run until some situation changes. Eventually, this will be ready to run again, which will put it from the blocked -> ready state. The scheduler The scheduler (or a dispatcher) has to pick things to run. It has to pick one of its ready threads to start! How does it do taht though... We could have a queue! the scheduler picks from the head of the queue!! What about blocked processes though? When an unblocking event happens (file is read, keyboard is inputted, network is recieved/sent), we could scan through all processes to check which processes to unblock, but thats inefficient! We could have a queue of blocked tasks for each blocked event, which will then trigger and push it to the end of the ready queue. Concurrency Consider two pieces of code which shares a global varialbe count . void increment() { int t; t = count; t = t + 1; count = t; } void decrement() { int t; t = count; t = t - 1; count = t; } if both pieces of code were to be ran, there could be a race condition! imagine if the increment() thread were to hand over control to the decrement() thread after t = t+1 This would mean that after decrement, count is decresed by 1. However, when the thread is handed back to increment(), count would be count + 1, intead of 0. Kernel level concurrency Think back on scheduling. To run our dispatcher (scheudler), we would need a kernel level thread to execute that dispatcher, right? That would mean keeping track of queues of ready and blocked processes. Likewise, we need to upkeep the PCB (process control block) to ensure metadat is kept up to date. Critical regions A critical region is a position where a shared location is accessed. If uncorrindated access to this is done, then it coudl result in race conditions or other nasty stuff to ensure protection within critical regions, we can force different processes to wait until their turn: A enteres critical region /-------------\\ Process A: ------------------------===============---------------------------- Process B: -----------------------------..........===========----------- \\---------/ B attempts to access critical region, fails. solving critical regions We need to coordinate access to critical regions! We need to: - mutually exclude processes accessing critical regions - make no assumptions about the number of threads - no process running outside the critical region can block another process (defeats whole point of multitrheading) - no process waits forever to enter critical region! Locks!! We could haev a global lock varaible that won't let code execute if it is true. Code that did enter the critical region would set lock = 1 and when its done will lock = 0 while(TRUE) { while(lock == 1) ; lock = 1; critical(); lock = 0 non_critical(); } while(TRUE) { while(lock == 1) ; lock = 1; critical(); lock = 0 non_critical(); } However, another issue may be posed: if the while(lock == 1) condition has passed for a process, then the thread is handed over to the other process, both locks will be 1, and the critical region will be hit! what do we do?? taking turns We could take turns!! We have a global turn variable that specifies which thread is allowed to run (i.e. turn = 0 represents process A, =1 represents process B, etc) The problem with taking turns is that processes must wait to take their turn, even if other processes are doing something else. hardware support You can actually disable interrupts! its a builtin thing via hardware. The downsides is that it delays everyone else, and it doesnt work on multiprocessors :( test and set another hardware instruction! It's atomic, meaning that its the smallest unit of instruciton executable. Using this, it can test the value of a lock AND set it at the same time.","title":"What is an OS?"},{"location":"comp3891/w1/#what-is-an-os","text":"An operating system is the abstraction that helps connect userspace and hardware! There are many layers of abstractions built for us: we have C code thats been compiled, which relies on system libraries (think cstdlib), which makes use of syscalls which are provided by the OS! e.g. We never manually interact with the filesystem Distribute resources! Imagine multiple users (or processes) trying to run their program. How do we choose who evently recieves what data? the operating system is in charge of that! It could be done through a policy as well (quota, first come first serve, etc) from the perspective of the system, the OS is the software running in priviliged mode! this could be like ring0 or whatever but there are physical hardware checks (think lgdt, tss, etc in x86) Theres a flag set in hardware that shows if the current software can do more stuff (accesss memory, etc)","title":"What is an OS?"},{"location":"comp3891/w1/#structure-of-a-system","text":"Theres two 'bubbles' of a system: We usually have userspace and kernel mode. Applications in userspace make use of system libraries; which are just normal libraries as well. Its just ordinary code that interacts with the kernel to get stuff done. If you think about it, everything lives somewhere on memory. The operating system has the ability to view memory and theres some memory that can only be touched by the OS. If processes want to do stuff that involve os actions, they need to make use of syscalls, which are like function calls but its a protected way of nicely asking the os to do something for you. These can be written by yourself but most often you want to do them via syscalls (open, close, read, etc). These syscalls are then created to have another abstraction layer (malloc, memcpy, etc) tldr; the operating system is just code that has more power and that lets it interact with hardware (like memory)","title":"Structure of a system?"},{"location":"comp3891/w1/#system-approaches","text":"How should we arrange an OS internally? There is a layered by layer approach: dependencies point downwards into the core of the system. For instance, the usermode would be in the shell of the system, with layers of abstraction behind each other, with processor management and memoryu management at the core! However, this isn't really realistic. A different implimentation is a monolithic kernel; everything is interlinked with everything else! Think linux, windows, etc. However, a general prevailing structure will usually form.","title":"System approaches"},{"location":"comp3891/w1/#processes-and-threads","text":"Remember how we said the os needs to be able to run more than one thing? The processor will give the os the ability to do so, but the processor itself cannot run more than one thing at once unless you have multithreading: but you still want more processes than you ahve threads.","title":"Processes and threads"},{"location":"comp3891/w1/#what-is-a-process-what-is-a-thread","text":"A process is closer to an abstraction of a thing that \"runs\", or a user level execution. It owns resources allocated for program execution. It encompasses one more more threads. A thread is the sequence of instruciotns that are ran. Think of processes as a space in memory of a thing to be executed, and a thread being the instructions that make up that process being ran","title":"what is a process? what is a thread?"},{"location":"comp3891/w1/#the-thread-model","text":"Assume there is a multithreaded process: At the langauge level; that means that each thread within the process has its own separate stack that can still share state (global varaibles) since they live in the same memory. But for local variables, they should have their own local variables (per thread)","title":"the thread model"},{"location":"comp3891/w1/#scope","text":"local varialbes are per thread global variables are shared (written in the .bss segment i think) dynamically allocated variables could be local OR global... (think malloc() )","title":"scope"},{"location":"comp3891/w1/#scheduling","text":"So how do we run muiltiple processes on one thread? We can have a dispatcher (scheduler) that decides which process to run by having each process run for a few instructions, before returning back to the dispatcher which makes a jump. States have to be preserved in between (storing register data), loaded and restored. Using this, it appeares that multiple processes are running at once, but in reality only one program is active at one point. Thus, there is a model of having sequential processes with a single thread each \"running\" at the same time.","title":"Scheduling"},{"location":"comp3891/w1/#when-do-we-return-back-to-the-dispatcher","text":"If you remember from our example of having programs scheduled in between, we jump between different processes by having program A run for a few instruction cycles before returning back to the dispatcher, which then decides on the next ready process to execute. How do we actually return back to the dispatcher in that instance? There is a feature within the CPU when certain hardware needs attention, it asks the CPU to stop executing its current instructions and then transition to the interrupt handler within the OS. Like a syscall, it forces a transition to the OS to timeout threads that have met its quota and transitions to the dispatcher (scheduler).","title":"When do we return back to the dispatcher?"},{"location":"comp3891/w1/#how-are-processes-created","text":"The os doesn't like setting things itself; it likes being reactive. Normally, that means handing it over to an init system (think systemd and openrc) that handles starting up other processes and etc. Theres different types of processes as well: foreground processes and background processes (known as daemons) Processes can start other processes as well! think login prompts that start you into a desktop environment once you login. All these processes mostly just make use of one syscall to create new processes!","title":"How are processes created?"},{"location":"comp3891/w1/#how-to-processes-end","text":"normal exit (return 0) error exit (exit(1)) fatal error (runtime error, div 0) kileld by another process (sigterm, ctrl-c)","title":"how to processes end?"},{"location":"comp3891/w1/#implementation-of-processes","text":"What does the code/data that implements a process look like? It needs to hold metadata for the os to make use of, and is held within the process control block (PCB). The PCBs form a process table that shows Assume this is for a single thread/process model: process metadata would include: registers, program counter, stack pointer, process state, pointers to stack, text, data segments, process ID, cpu time used, children of CPU time, etc. these all are used by the operating system to control and make use of processes, like scheduling or terminating based off other processes.","title":"implementation of processes"},{"location":"comp3891/w1/#threadsprocess-states","text":"there can be alot of variable thread or process states. Ideally, we should have as many running processes as there are threads in cpus. running -> ready - voluntary yield() - end of timeslice (quota) ready -> running running -> blocked - waiting for input (file, network, keyboard) - waiting for a timer sleep() - waiting for a resource to become avaliable blocked -> ready for the transition from runnign to ready for a thread, this could be a thread that is currently running, but its time budget is now used up and will be reassigned to a different process! It's still ready to run, its just not one of the ready threads. For ready -> running, the currently running task got stopped so we need to replace the thread to keep the cpu busy. For running -> blocked, something like a syscall could happen: a process wants to sleep(), or the process wants to use a syscall to fetch file contents. Its not current avaliable, so the thread becomes blocked. It's not allowed to run until some situation changes. Eventually, this will be ready to run again, which will put it from the blocked -> ready state.","title":"Threads/Process states"},{"location":"comp3891/w1/#the-scheduler","text":"The scheduler (or a dispatcher) has to pick things to run. It has to pick one of its ready threads to start! How does it do taht though... We could have a queue! the scheduler picks from the head of the queue!! What about blocked processes though? When an unblocking event happens (file is read, keyboard is inputted, network is recieved/sent), we could scan through all processes to check which processes to unblock, but thats inefficient! We could have a queue of blocked tasks for each blocked event, which will then trigger and push it to the end of the ready queue.","title":"The scheduler"},{"location":"comp3891/w1/#concurrency","text":"Consider two pieces of code which shares a global varialbe count . void increment() { int t; t = count; t = t + 1; count = t; } void decrement() { int t; t = count; t = t - 1; count = t; } if both pieces of code were to be ran, there could be a race condition! imagine if the increment() thread were to hand over control to the decrement() thread after t = t+1 This would mean that after decrement, count is decresed by 1. However, when the thread is handed back to increment(), count would be count + 1, intead of 0.","title":"Concurrency"},{"location":"comp3891/w1/#kernel-level-concurrency","text":"Think back on scheduling. To run our dispatcher (scheudler), we would need a kernel level thread to execute that dispatcher, right? That would mean keeping track of queues of ready and blocked processes. Likewise, we need to upkeep the PCB (process control block) to ensure metadat is kept up to date.","title":"Kernel level concurrency"},{"location":"comp3891/w1/#critical-regions","text":"A critical region is a position where a shared location is accessed. If uncorrindated access to this is done, then it coudl result in race conditions or other nasty stuff to ensure protection within critical regions, we can force different processes to wait until their turn: A enteres critical region /-------------\\ Process A: ------------------------===============---------------------------- Process B: -----------------------------..........===========----------- \\---------/ B attempts to access critical region, fails.","title":"Critical regions"},{"location":"comp3891/w1/#solving-critical-regions","text":"We need to coordinate access to critical regions! We need to: - mutually exclude processes accessing critical regions - make no assumptions about the number of threads - no process running outside the critical region can block another process (defeats whole point of multitrheading) - no process waits forever to enter critical region!","title":"solving critical regions"},{"location":"comp3891/w1/#locks","text":"We could haev a global lock varaible that won't let code execute if it is true. Code that did enter the critical region would set lock = 1 and when its done will lock = 0 while(TRUE) { while(lock == 1) ; lock = 1; critical(); lock = 0 non_critical(); } while(TRUE) { while(lock == 1) ; lock = 1; critical(); lock = 0 non_critical(); } However, another issue may be posed: if the while(lock == 1) condition has passed for a process, then the thread is handed over to the other process, both locks will be 1, and the critical region will be hit! what do we do??","title":"Locks!!"},{"location":"comp3891/w1/#taking-turns","text":"We could take turns!! We have a global turn variable that specifies which thread is allowed to run (i.e. turn = 0 represents process A, =1 represents process B, etc) The problem with taking turns is that processes must wait to take their turn, even if other processes are doing something else.","title":"taking turns"},{"location":"comp3891/w1/#hardware-support","text":"You can actually disable interrupts! its a builtin thing via hardware. The downsides is that it delays everyone else, and it doesnt work on multiprocessors :(","title":"hardware support"},{"location":"comp3891/w1/#test-and-set","text":"another hardware instruction! It's atomic, meaning that its the smallest unit of instruciton executable. Using this, it can test the value of a lock AND set it at the same time.","title":"test and set"},{"location":"comp3891/w2/","text":"os161 mips We are using mips r3000! risc architecture (reduced isa) some instruction shave imediate operands values are constants within the instruction itself addi r2, r1, 2048 instruction format: | ADD | IMM | R2 | R1 | 2048 | registers! 32 general purpose registers r0 hardwired to 0 r31 is a jal (jump and link) hi/lo are two 32 bits for multiply and divide PC is the program counter Branches and jmumping branches and jumping have a branch delay slot the instruction following a branch or jump is always executed prior to destination of jump this means that the instruction after the jump or branch is executed ontop before the branch happens why does this happen? there are stages of executing an instruction! load instruction register file load into ALU D-cache register fileo the instructions don't get loaded at the same time! instruction 1: ------| IF | RD | ALU | MEM | WB |---------------------------- instruction 2: --------------| IF | RD | ALU | MEM | WB |-------------------- instruction 3: ----------------------| IF | RD | ALU | MEM | WB |------------ jump and link used to implement function calls return register ra is used to return from function call mips register conventions (2-3) v0-v1: value returned by subroutine (4-7) a0-a3: first four parameters for subroutine (16-23) s0-s7: subroutine variables which must store and restore it (28) gp: global pointer for some systems to maintained to the global point (29) sp: stack pointer jumping to subroutines when we switch/jump to a subroutine, we push the values we want to save to the stack before we jump! doing this repeatedly we can create stack frames on stack frames so we preserve the state of the current subprocess even if we call other processes. context switches a context switch can refer to: a switch between threads saving, restoring state associated with a thread a switch between processes process abstrations! os structure from the hardware as the lowest level, you can haev layers of os functionality: from top down: monolithic kernel processes | usermode os services: Files, networking, etc ---- ABI scheduler | kernel dispatcher ---- ISA hardware and the kernel is the blanket term for the content between abi and ISA but generally, you want to shrink the maount of code that is runnign in privileged mode. This means you can take out the os serves out of the kernel as a library micro/exokernel processes | usermode os services | scheduler ---- | priviliged mode (kernel) dispatcher ---- hardware library OS! Since we could switch out the tailord OS services (system libraries), we can swap them out and run processes on TOP of different system libraries (bootstrap with different init systems) using this, these libraries give different \"flavours\" of the operating system. However, the library os's (think libc) aren't really secure and have simplified resource maagements. This means that functionally, they are insecure!! As a result, you need a security monitor layer ontop of the dispatcher within priviliged mode. The drawbridge system Traditionally, library os's change the api. that means that applications written aren't exactly portable beyond one library os. Drawbridge refactors the OS! You have a set of API compatible OS services within the library that makes use of host OS kernel services. Picoprocesses picoprocesses are an isolated process weith different syscall interface than normal processes. In this case, it could be a security monitor! (I dont fully understand picoprocesses, but to my understanding its just a process that only uses kernel syscalls) back to virtual machines","title":"os161 mips"},{"location":"comp3891/w2/#os161-mips","text":"We are using mips r3000! risc architecture (reduced isa) some instruction shave imediate operands values are constants within the instruction itself addi r2, r1, 2048 instruction format: | ADD | IMM | R2 | R1 | 2048 | registers! 32 general purpose registers r0 hardwired to 0 r31 is a jal (jump and link) hi/lo are two 32 bits for multiply and divide PC is the program counter","title":"os161 mips"},{"location":"comp3891/w2/#branches-and-jmumping","text":"branches and jumping have a branch delay slot the instruction following a branch or jump is always executed prior to destination of jump this means that the instruction after the jump or branch is executed ontop before the branch happens","title":"Branches and jmumping"},{"location":"comp3891/w2/#why-does-this-happen","text":"there are stages of executing an instruction! load instruction register file load into ALU D-cache register fileo the instructions don't get loaded at the same time! instruction 1: ------| IF | RD | ALU | MEM | WB |---------------------------- instruction 2: --------------| IF | RD | ALU | MEM | WB |-------------------- instruction 3: ----------------------| IF | RD | ALU | MEM | WB |------------","title":"why does this happen?"},{"location":"comp3891/w2/#jump-and-link","text":"used to implement function calls return register ra is used to return from function call","title":"jump and link"},{"location":"comp3891/w2/#mips-register-conventions","text":"(2-3) v0-v1: value returned by subroutine (4-7) a0-a3: first four parameters for subroutine (16-23) s0-s7: subroutine variables which must store and restore it (28) gp: global pointer for some systems to maintained to the global point (29) sp: stack pointer","title":"mips register conventions"},{"location":"comp3891/w2/#jumping-to-subroutines","text":"when we switch/jump to a subroutine, we push the values we want to save to the stack before we jump! doing this repeatedly we can create stack frames on stack frames so we preserve the state of the current subprocess even if we call other processes.","title":"jumping to subroutines"},{"location":"comp3891/w2/#context-switches","text":"a context switch can refer to: a switch between threads saving, restoring state associated with a thread a switch between processes","title":"context switches"},{"location":"comp3891/w2/#process-abstrations","text":"","title":"process abstrations!"},{"location":"comp3891/w2/#os-structure","text":"from the hardware as the lowest level, you can haev layers of os functionality: from top down:","title":"os structure"},{"location":"comp3891/w2/#monolithic-kernel","text":"processes | usermode os services: Files, networking, etc ---- ABI scheduler | kernel dispatcher ---- ISA hardware and the kernel is the blanket term for the content between abi and ISA but generally, you want to shrink the maount of code that is runnign in privileged mode. This means you can take out the os serves out of the kernel as a library","title":"monolithic kernel"},{"location":"comp3891/w2/#microexokernel","text":"processes | usermode os services | scheduler ---- | priviliged mode (kernel) dispatcher ---- hardware","title":"micro/exokernel"},{"location":"comp3891/w2/#library-os","text":"Since we could switch out the tailord OS services (system libraries), we can swap them out and run processes on TOP of different system libraries (bootstrap with different init systems) using this, these libraries give different \"flavours\" of the operating system. However, the library os's (think libc) aren't really secure and have simplified resource maagements. This means that functionally, they are insecure!! As a result, you need a security monitor layer ontop of the dispatcher within priviliged mode.","title":"library OS!"},{"location":"comp3891/w2/#the-drawbridge-system","text":"Traditionally, library os's change the api. that means that applications written aren't exactly portable beyond one library os. Drawbridge refactors the OS! You have a set of API compatible OS services within the library that makes use of host OS kernel services.","title":"The drawbridge system"},{"location":"comp3891/w2/#picoprocesses","text":"picoprocesses are an isolated process weith different syscall interface than normal processes. In this case, it could be a security monitor! (I dont fully understand picoprocesses, but to my understanding its just a process that only uses kernel syscalls)","title":"Picoprocesses"},{"location":"comp3891/w2/#back-to-virtual-machines","text":"","title":"back to virtual machines"},{"location":"comp3891/w3/","text":"Context switching! what happens when an interrupt (context switch) occurs? - hardware stacks program counter - hardware loads new program counter from interrupt vector - assembly lanauge saves registers - assembly language sets up new stack - C interrupt service runs - scheduler decides which process is to run next - C procedure returns to assembly code - assembly language starts up new process But what actually is a context switch?? a context switch can either mean: - a swithc between threads - saving, restoring state associated with a thread - a switch between processes - thread switch stuff and on top of that with the extra process state stuff (memory) When do context switches happen? when a syscall happens on an exception on an interrupt includes timing interrupts (schedulers!) A thread swtich can happen between any two instructions! How do we preform a context switch? the goal is to create a thread that we can context swithc away from, and to be context switched back to. The userleverl thread won't notice this switch. That means that when we suspend a thread, we need to take all its context (the stuff that explains what its instructions mean, like registers, sp, pc) and restore its memory. os161? in os161, we have a thread switch mechanism where a thread can choose to participate in, which causes its stack to be suspended and transferred to another thread. Cooperative concurrency","title":"Context switching!"},{"location":"comp3891/w3/#context-switching","text":"what happens when an interrupt (context switch) occurs? - hardware stacks program counter - hardware loads new program counter from interrupt vector - assembly lanauge saves registers - assembly language sets up new stack - C interrupt service runs - scheduler decides which process is to run next - C procedure returns to assembly code - assembly language starts up new process But what actually is a context switch?? a context switch can either mean: - a swithc between threads - saving, restoring state associated with a thread - a switch between processes - thread switch stuff and on top of that with the extra process state stuff (memory)","title":"Context switching!"},{"location":"comp3891/w3/#when-do-context-switches-happen","text":"when a syscall happens on an exception on an interrupt includes timing interrupts (schedulers!) A thread swtich can happen between any two instructions!","title":"When do context switches happen?"},{"location":"comp3891/w3/#how-do-we-preform-a-context-switch","text":"the goal is to create a thread that we can context swithc away from, and to be context switched back to. The userleverl thread won't notice this switch. That means that when we suspend a thread, we need to take all its context (the stuff that explains what its instructions mean, like registers, sp, pc) and restore its memory.","title":"How do we preform a context switch?"},{"location":"comp3891/w3/#os161","text":"in os161, we have a thread switch mechanism where a thread can choose to participate in, which causes its stack to be suspended and transferred to another thread.","title":"os161?"},{"location":"comp3891/w3/#cooperative-concurrency","text":"","title":"Cooperative concurrency"}]}